# TBNF Grammar

TBNF is a language for specifying a variant of parser expression grammars.
Successful output from a TBNF grammar is a t-expression containing, in-order,
  every character of the original input.
TODO: describe what's different about tbnf vs peg.

## Large-Scale Structure

TBNF grammars are defined with a syntax similar to ABNF/ABNF.
The first notable difference however, is that TBNF is written in a literate coding style.
This allows for documentation of a grammar to be placed directly alongside the grammar itself.
In fact, you are reading a TBNF grammar _right now_.
Compare this to regular expression syntax, which focuses on the technical details, but which is notoriously write-only code.

In bird-style literate programming,
  all the lines of code are prefixed by a "bird foot",
  and all other lines are automatically considered documentation.
I personally recommend using Markdown syntax for documentation sections.
The name comes from the apparent resemblance of the greater-than sign
  to the footprint of a bird.

Here is the corresponding code that implements detecting bird feet and documentation lines.
Exactly how this syntax works will be explained later.
For now, the syntax should resemble familiar grammar definitions enough so that
  you won't have much issue reading it.
Note however, that identifiers followed by a colon indicate a "constructor",
  which will appear in the final output,
  wrapping the match of the grammar to the right of the colon.

> birdFoot = bird-foot: '>' ' '
> doc.line = doc:
>   / [^ >'\n' ]   # one character on the line that is not `>`
>     [^ '\n'  ]*  # any other characters on the line
>   /
>
> Doc = (doc.line nl? | nl)+

Beyond documentation, TBNF grammars consist of definitions (the `Def` rule).
These definitions are interspersed between documentation.
We can see that definitions begin at the start of a line, and there may be linear whitespace (`lws`) trailing the line.
Additionally, it is possible to have blank code lines, called here "vertical whitespace" `vws`.
Before moving on to definitions, I'll describe what is allowed for both linear and vertical whitespace.

> start = top* $
>
> top
>   = Doc
>   | birdFoot Def lws* (nl | $)
>   | vws
>
> nl = nl: '\n'

Linear whitespace includes both space characters and inline comments.
Comments are preceded by a hash and continue to the end of the line.

> space = space: /' '+/
> comment = comment: '#' /[^'\n']*/

Additionally, if a code line is indented (in absolute terms), then it is effectively part of the previous line.
Blank code lines also do not contribute, so we also need to account for blank lines which consist _only_ of a greater-than symbol: thus, we introduce "improper" bird feet.
Note that these are wrapped in the same constructor as plain bird feet (including a space after the greater-than).
The same constructor may be used as many times in as many places as one likes.

> birdFoot.improper = bird-foot: '>' '\n'

With those preliminaries dealt with, we can easily read the definition of linear whitespace (lws).
Spaces, comments, and indented lines following blank code lines.
In this grammar we will generally use `lws*` and `lws+` because whitespace is sometimes optional and sometimes required.
TODO: Note that documentation is not allowed to come in the middle of a definition (I'm not sure that's a good thing to allow).

> lws = space
>     | comment
>     | nl birdFoot.improper* birdFoot lws

Vertical whitespace, on the other hand, consists of lines that contain at most linear whitespace.

> vws = birdFoot space* comment? nl
>     | birdFoot.improper

## Definitions

A TBNF grammar consists of two parts: a set of rules/productions/non-terminals, and a start rule.
If no start rule is specified, then it is by default whatever rule is named `start`.
Otherwise, one may define a start rule with the following syntax:

> Def.Start = def-start: "@start" lws+ '=' lws+ Name.rule

While rules in context-free grammars or parser expression grammars are simply given a name,
  rules in TBNF may be parameterized.
This allows for code re-use across (potentially infinite) families of related grammars.

> Def.Rule = def-rule: Def.Rule.lhs lws+ '=' lws+ Rule.allowFlat
>
> Def.Rule.lhs = rule-parametric:
>                 Name.rule enclose.angles<sep.comma<Name.param>>
>              | Name.rule

There is one other sort of definition, which aids in defining rules: the character class definition.
These are effectively shortcuts used to specify which individual characters are permitted during parsing.

> Def.Class = def-class: enclose.colon<Name.class> lws+ '=' lws+ Class

Together, these are the three sorts of definition possible in TBNF.

> Def = Def.Start | Def.Class | Def.Rule

TODO? global rules are upcase, local rules and captures are locase

TODO In future versions, there will likely be support for importing definitions from other files (with or without qualifying the names), and extending existing rules with additional alternatives; the latter will definitely help the structure of this document!

## Rules

Let's begin by defining the smallest possible rules and work up from there.

- The simplest possible rule is recognizing a single, specific character.
  This is written as that character in single quotes.
- Or, one might allow a variety of characters, which we write with a special syntax inside square brackets.
  We'll come back to that syntax in a moment.
  Writing a caret immediately after the open bracket inverts the allowed set.
- One might sequence many specific characters in a row, i.e. a string.
  These are written inside double-quotes.
  Unlike writing a sequence of isolated (i.e. single-quote) characters, a string is matched as a whole, so errors are reported at the start of the string, even if a prefix matches.
- One might also require there to be _no_ characters at a position: that is,
  requiring one has reached the end of input.
  This is written (as in regex) with a dollar sign.
- Finally, to round out the algebra of grammars, we include the zero-rule (a.k.a. void),
    which always fails, no matter the input.
  For good error reporting, we require this void grammar to come along with an error message,
    just in case it is ever the source of a parse failure.

> Rule.prim
>   = rule-char: '\'' char.sq '\''
>   | rule-sat: ("[^" | '[') Rule.satisfy.part* ']'
>   | rule-string: '\"' chars.dq* '\"'
>   | rule-end: '$'
>   | rule-void: '0' colon '\"' chars.dq+ '\"'

To match one of a variety of characters, we enclosing the options in square brackets.
Specifying these options can be done by specifying individual characters,
  with a range, or by giving the name of a defined character class inside colons.
While any character can be given inside single quotes,
  the quotes are not necessary for many common characters, and can be dropped.
Whitespace inside the brackets is ignored.

> Rule.satisfy.part
>   = sat-range: '\'' char.sq '\'' ".." '\'' char.sq '\''
>   | sat-char: '\'' char.sq '\''
>   | sat-var: enclose.colon<Name.class>
>   | / [:char.brack:]+ /
>   | lws

More complex grammars are built from these primitives by combination by various operators.
These operators have a precedence, which we will go through from highest-to-lowest (i.e. smallest-to-largest).

The highest-precedence of these are grouping (parenthesis), flattening (slashes), and non-terminals (calls).
Here we see our first parametric rule definition; for now, I'll just say that parameters and arguments
  are surrounded by angle brackets and separated by commas.
In fact, that is just what the `rule-call: …` alternative states.

> Rule.Atom<f>
>   = rule-group: enclose.parens<Rule.allowFlat>
>   | rule-call: Name.rule enclose.angles<sep.comma<Rule.allowFlat>>?
>   | rule-flat: f
>   | Rule.prim
>
> Rule.Flat = enclose<'/', Rule.disallowFlat, '/'>

Because the open and close delimiters of `Rule.Flat` are identical,
  we cannot allow a flatten operator directly inside another flatten operator.
This restriction will affect a large number of rules involved in operator precedence.
Rather than define two separate chains of rules
  (which increases the grammar's size and makes it possible for
    the two grammars to get out of sync as changes are made),
  we instead parameterize every rule in the chain with whether flattening is allowed.
We've chosen the convention of doing this with the `f` parameter in this grammar.
This `f` parameter will only be filled with one of two grammars,
  one to allow it and another to disallow it.

> Rule.allowFlat = Rule<Rule.Flat>
> Rule.disallowFlat = Rule<0: "flat rule inside flat">

Our next set of operators are repetition operators.
This includes the usual star, plus, question mark, and bounded repetition (curly braces) from regex.

> Rule.Factor<f>
>   = rule-rep: Rule.Atom<f> Rule.Rep.amount
>   | Rule.Atom<f>
>
> Rule.Rep.amount
>   = [*+?]
>   | rep-custom: enclose.braces<num.nat? comma num.nat?>
>   | rep-custom: enclose.braces<num.nat>

Our next operator is sequencing, which is marked simply by separating grammars with whitespace.
It is also possible to capture input, then replay it in subsequent input.
Note that unlike regex, replays are valid only within a given scope, rather than for the remainder of the parse.
Also, captures are always given names, never referred to by numbers.

> Rule.Seq<f>
>   = rule-capture: '@' Name.rule lws* '=' lws+ Rule.Factor<f> lws+ Rule.Seq<f>
>   | rule-seq: Rule.Factor<f> (lws+ Rule.Factor<f>)+
>   | Rule.Factor<f>

Then, we have our constructor rule, which we have already seen in use.

> Rule.Term<f>
>   = rule-ctor: Name.ctor colon Rule.Seq<f>
>   | Rule.Seq<f>

Finally, we have alternation, which is done with 
As in PEGs, this is ordered choice, so it introduces no ambiguity.

> Rule<f>
>   = rule-alt: Rule.Term<f> (lws+ '|' lws+ Rule.Term<f>)+
>   | Rule.Term<f>

## Character Classes

Character classes are simply sets of admissible Unicode characters.
The only operators are union and difference, which have the same associativity,
  and are right-associative.

> Class = Class.term (lws+ Class.operator lws+ Class.term)*
> Class.operator = '|' | '-'

As for the primitive sets, there are:
- A single character, in single quotes.
- A select few characters, in double quotes.
- A range of characters, written as dobule-dots between the single-quoted (inclusive) endpoints.
- Another named character class.

> Class.term
>   = class-var: enclose.colon<Name.class>
>   | class-range: '\'' char.sq '\'' ".." '\'' char.sq '\''
>   | class-char: '\'' char.sq '\''
>   | class-set: '\"' chars.dq* '\"'

## Supporting Definitions

Finally, we've been using all sorts of rules above that are likely easily-guessable
  based on one's knowledge of other grammars, and the examples already given.
We still need to define them for the computer though, so I'll go through these quickly.

### String and Character Literals

Single- and double-quoted strings admit the usual backslash-based escape sequences.
TODO right now, unescaped is just ASCII, but should probably include Unicode printing chars

> char.sq
>   = [:char.sq:]
>   | char.escape
> :char.sq: = ' '..'~' - "\'\\"
>
> chars.dq
>   = /[:char.dq:]+/
>   | char.escape
> :char.dq: = ' '..'~' - "\"\\"
>

The actual set of escape sequences is close to C, with `\x`, `\u`, and `\U`
  allowing different sizes of character.
Note that simple backslash-digits is not allowed (it can be ambiguous), though `\0` _is_ allowed.
Also, we include `\e` for ASCII escape, just because it is common enough in other languages.

> char.escape
>   = char-escape: / '\\' [:char.escape.c:] /
>   | char-escape: "\\x" /[:digit.hex:]{2}/
>   | char-escape: "\\u" /[:digit.hex:]{4}/
>   | char-escape: "\\U"
>                     / '0' [:digit.hex:]{5}
>                     | "10" [:digit.hex:]{4}
>                     /
>   | char-escape: '\\' [:char.escape.passthru:]
> :char.escape.c: = "0abefnrtv"
> :char.escape.passthru: = :ascii.print: - :char.escape.c: - "xuU"

The (unquoted) characters admissible within square brackets are quite different.
In particular, we've gone a bit overboard disallowing certain characters that
  wouldn't otherwise cause a problem wit hthe syntax.
However, we thought it best to disallow them to reduce confusion
  by removing some characters that usually have special meaning in regex,
  and ensuring symmetry in the definition

> :char.brack: = :ascii.print: - " []\'\"-:\\"

### Names

Names appear in a variety of places in the grammar.
We've collected them here so that one can see at a glance what is allowed.
Generally, they are alphanumeric strings separated with dots and/or dashes.

> Name.rule = / sep.dot<[:ascii.alpha:] [:ascii.alpha-num:]*> /
>
> Name.param = / [:ascii.alpha:] [:ascii.alpha-num:]* /
>
> # TODO: should this really by separated by dash? seems incongruent
> Name.ctor = / sep.dash<[:ascii.alpha:] [:ascii.alpha-num:]*> /
>
> Name.class = / sep.dot<[:ascii.alpha:] [:ascii.alpha-num:'\-']*> /

### Generic Character Classes

These character class definitions are widely-used notions.
Once grammar libraries/import is implemented, these will be moved to a library.

> :ascii.print: = ' '..'~'

> :digit: = '0'..'9'
> :digit.hex: = :digit: | 'a'..'f' | 'A'..'F'

> :ascii.alpha: = :ascii.alpha.lo: | :ascii.alpha.hi:
> :ascii.alpha.lo: = 'a'..'z'
> :ascii.alpha.hi: = 'A'..'Z'
> :ascii.alpha-num: = :ascii.alpha: | :digit:

Ah yes, and we also needed decimal natural numbers, which I may as well throw in here.

> num.nat = / [:digit:] [:digit:]* /

### General Combinators

And finally, there are a number of general-purpose grammar combinators.
These make it easy to describe conceptually-simple — but technically detailed — pieces of grammar.

> enclose<o,i,c> = o lws* i lws* c
>
> enclose.parens<i> = enclose<'(',i,')'>
> enclose.braces<i> = enclose<'{',i,'}'>
> enclose.angles<i> = enclose<'<',i,'>'>
> enclose.colon<i> = enclose<':',i,':'>

> sep.by<e,s> = e (s e)*
>
> sep.comma<e> = sep.by<e,comma>
> sep.dot<e> = sep.by<e,'.'>
> sep.dash<e> = sep.by<e,'-'>

> comma = lws* ',' lws*
> colon = lws* ':' lws+
